{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d1bcd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "044ec276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Alter function depending on format and interval of true data\n",
    "def reduce_resolution(data, interval=1):\n",
    "    \n",
    "    interval_values = {}\n",
    "\n",
    "    for timestamp, value in data:\n",
    "        # Find which interval this timestamp belongs to\n",
    "        interval_index = int(timestamp // interval)\n",
    "\n",
    "        # If not in add it\n",
    "        if interval_index not in interval_values:\n",
    "            interval_values[interval_index] = value\n",
    "        else:\n",
    "            # If any value is 1, set the interval to 1\n",
    "            interval_values[interval_index] = max(interval_values[interval_index], value)\n",
    "\n",
    "    # Convert to sorted list of (timestamp, value) pairs\n",
    "    reduced_data = []\n",
    "    for interval_index in sorted(interval_values):\n",
    "        reduced_timestamp = interval_index * interval\n",
    "        reduced_value = interval_values[interval_index]\n",
    "        reduced_data.append((reduced_timestamp, reduced_value))\n",
    "\n",
    "    return reduced_data\n",
    "\n",
    "def compute_confusion_matrix(sensor_data, true_data):\n",
    "    # Assume sensor_data and true_data are same size and interval\n",
    "    TP = FP = TN = FN = 0\n",
    "\n",
    "    for i in range(len(sensor_data)):\n",
    "        sensor_val = sensor_data[i][1]\n",
    "        true_val = true_data[i][1]\n",
    "        if sensor_val == 1 and true_val == 1:\n",
    "            TP += 1\n",
    "        elif sensor_val == 1 and true_val == 0:\n",
    "            FP += 1\n",
    "        elif sensor_val == 0 and true_val == 0:\n",
    "            TN += 1\n",
    "        elif sensor_val == 0 and true_val == 1:\n",
    "            FN += 1\n",
    "\n",
    "    confusion_matrix = np.array([\n",
    "        [TP, FP],\n",
    "        [FN, TN]\n",
    "    ])\n",
    "    return confusion_matrix\n",
    "\n",
    "# compute accuracy and positive predictive value\n",
    "def compute_metrics(confusion_matrix):\n",
    "    TP = confusion_matrix[0, 0]\n",
    "    FP = confusion_matrix[0, 1]\n",
    "    FN = confusion_matrix[1, 0]\n",
    "    TN = confusion_matrix[1, 1]\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "    ppv = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "    return accuracy, ppv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d82edd",
   "metadata": {},
   "source": [
    "# Generate Synthetic Data for testing while circuit still being built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e9bf129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data saved to 'test_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# !----------------- Generate synthetic data -----------------!\n",
    "\n",
    "# Simulate 10 seconds worth of data with 1000 samples\n",
    "sampling_rate = 100  # 100 samples per second\n",
    "\n",
    "num_samples = 1000  # Total 1000 samples\n",
    "interval_between_samples = 10 / num_samples  # 10 seconds divided by 1000 samples\n",
    "\n",
    "# Generate synthetic data: (timestamp in seconds, biased random 0 or 1)\n",
    "data = []\n",
    "last_one_timestamp = -float('inf')  # Initialize to negative infinity\n",
    "group_size = random.randint(50, 150)  # Randomize the number of consecutive 1s in a group to simulate vibration intensity\n",
    "\n",
    "for i in range(num_samples):\n",
    "    timestamp = i * interval_between_samples\n",
    "    # Ensure 1 occurs only if at least 2 seconds have passed since the last group of 1s\n",
    "    if timestamp - last_one_timestamp >= 2 and random.random() < 0.2:  # 20% chance to start a group of 1s\n",
    "        for _ in range(group_size):\n",
    "            if len(data) < num_samples:  # Ensure we don't exceed the total number of samples\n",
    "                data.append((timestamp, 1))\n",
    "                timestamp += interval_between_samples\n",
    "        last_one_timestamp = timestamp - interval_between_samples\n",
    "    else:\n",
    "        data.append((timestamp, 0))  # Bias towards 0\n",
    "\n",
    "# Write to CSV\n",
    "with open('test_data.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['timestamp', 'value'])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"Sample data saved to 'test_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52eac678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   timestamp  value\n",
      "0        0.0      0\n",
      "1        0.5      0\n",
      "2        1.0      0\n",
      "3        1.5      0\n",
      "4        2.0      0\n"
     ]
    }
   ],
   "source": [
    "f = pd.read_csv('sensor_data_22-23-08.csv', sep=',', header=None, names=['timestamp', 'value'])\n",
    "print(f.head())\n",
    "\n",
    "\n",
    "# Reduce resolution to 1 microsecond intervals\n",
    "#reduced_data = reduce_resolution(f, interval=0.5)\n",
    "reduced_data = f\n",
    "\n",
    "# print(\"Reduced data:\")\n",
    "# for timestamp, value in reduced_data:\n",
    "#     print(f\"Timestamp: {timestamp:.6f}, Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98fb6c8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m matrix = \u001b[43mcompute_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduced_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduced_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m accuracy, ppv = compute_metrics(matrix)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, PPV: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mppv\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mcompute_confusion_matrix\u001b[39m\u001b[34m(sensor_data, true_data)\u001b[39m\n\u001b[32m     28\u001b[39m TP = FP = TN = FN = \u001b[32m0\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sensor_data)):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     sensor_val = \u001b[43msensor_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     32\u001b[39m     true_val = true_data[i][\u001b[32m1\u001b[39m]\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sensor_val == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m true_val == \u001b[32m1\u001b[39m:\n",
      "\u001b[31mIndexError\u001b[39m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "matrix = compute_confusion_matrix(reduced_data['value'], reduced_data['value'])\n",
    "accuracy, ppv = compute_metrics(matrix)\n",
    "print(f\"Accuracy: {accuracy:.2f}, PPV: {ppv:.2f}\")\n",
    "\n",
    "# plot confusion matrix\n",
    "\n",
    "sns.heatmap(matrix, annot=True, fmt=\"d\", cmap=\"crest\", \n",
    "            xticklabels=['Actual 1', 'Actual 0'], \n",
    "            yticklabels=['Predicted 1', 'Predicted 0'])\n",
    "\n",
    "# Annotate each square with TP, FP, FN, TN slightly above the center\n",
    "for i, label in enumerate(['TP', 'FP', 'FN', 'TN']):\n",
    "    plt.text(i % 2 + 0.5, i // 2 + 0.3, label, ha='center', va='center', color='black', fontsize=12)\n",
    "\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc51b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trc3500",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
